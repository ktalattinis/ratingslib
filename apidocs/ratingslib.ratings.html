<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ratingslib.ratings package &mdash; ratingslib 1.0.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/style.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ratingslib.ratings.tests package" href="ratingslib.ratings.tests.html" />
    <link rel="prev" title="ratingslib.datasets.soccer module" href="ratingslib.datasets.soccer.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> ratingslib
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/examples.html">Applications &amp; Examples</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="ratingslib.html">ratingslib package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ratingslib.app_movies.html">ratingslib.app_movies package</a></li>
<li class="toctree-l2"><a class="reference internal" href="ratingslib.app_sports.html">ratingslib.app_sports package</a></li>
<li class="toctree-l2"><a class="reference internal" href="ratingslib.datasets.html">ratingslib.datasets package</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">ratingslib.ratings package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.tests.html">ratingslib.ratings.tests package</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.accurate.html">ratingslib.ratings.accurate module</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.aggregation.html">ratingslib.ratings.aggregation module</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.colley.html">ratingslib.ratings.colley module</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.elo.html">ratingslib.ratings.elo module</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.keener.html">ratingslib.ratings.keener module</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.markov.html">ratingslib.ratings.markov module</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.massey.html">ratingslib.ratings.massey module</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.methods.html">ratingslib.ratings.methods module</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.metrics.html">ratingslib.ratings.metrics module</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.od.html">ratingslib.ratings.od module</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.rating.html">ratingslib.ratings.rating module</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.winloss.html">ratingslib.ratings.winloss module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ratingslib.tests.html">ratingslib.tests package</a></li>
<li class="toctree-l2"><a class="reference internal" href="ratingslib.utils.html">ratingslib.utils package</a></li>
<li class="toctree-l2"><a class="reference internal" href="ratingslib.application.html">ratingslib.application module</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ratingslib</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="ratingslib.html">ratingslib package</a> &raquo;</li>
      <li>ratingslib.ratings package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/apidocs/ratingslib.ratings.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="module-ratingslib.ratings">
<span id="ratingslib-ratings-package"></span><h1>ratingslib.ratings package<a class="headerlink" href="#module-ratingslib.ratings" title="Permalink to this heading"></a></h1>
<p>Python package for Rating methods
This package includes the implementation of the following rating methods:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>WinLoss : <a class="reference internal" href="ratingslib.ratings.winloss.html#module-ratingslib.ratings.winloss" title="ratingslib.ratings.winloss"><code class="xref py py-mod docutils literal notranslate"><span class="pre">winloss</span></code></a></p></li>
<li><p>Colley : <a class="reference internal" href="ratingslib.ratings.colley.html#module-ratingslib.ratings.colley" title="ratingslib.ratings.colley"><code class="xref py py-mod docutils literal notranslate"><span class="pre">colley</span></code></a></p></li>
<li><p>Massey : <a class="reference internal" href="ratingslib.ratings.massey.html#module-ratingslib.ratings.massey" title="ratingslib.ratings.massey"><code class="xref py py-mod docutils literal notranslate"><span class="pre">massey</span></code></a></p></li>
<li><p>Elo : <a class="reference internal" href="ratingslib.ratings.elo.html#module-ratingslib.ratings.elo" title="ratingslib.ratings.elo"><code class="xref py py-mod docutils literal notranslate"><span class="pre">elo</span></code></a></p></li>
<li><p>Keener : <a class="reference internal" href="ratingslib.ratings.keener.html#module-ratingslib.ratings.keener" title="ratingslib.ratings.keener"><code class="xref py py-mod docutils literal notranslate"><span class="pre">keener</span></code></a></p></li>
<li><p>OffenseDefense : <a class="reference internal" href="ratingslib.ratings.od.html#module-ratingslib.ratings.od" title="ratingslib.ratings.od"><code class="xref py py-mod docutils literal notranslate"><span class="pre">od</span></code></a></p></li>
<li><p>AccuRATE : <a class="reference internal" href="ratingslib.ratings.accurate.html#module-ratingslib.ratings.accurate" title="ratingslib.ratings.accurate"><code class="xref py py-mod docutils literal notranslate"><span class="pre">accurate</span></code></a></p></li>
<li><p>GeM : <a class="reference internal" href="ratingslib.ratings.markov.html#module-ratingslib.ratings.markov" title="ratingslib.ratings.markov"><code class="xref py py-mod docutils literal notranslate"><span class="pre">markov</span></code></a></p></li>
</ol>
</div></blockquote>
<p>Several evaluation metrics that related with rating methods are included in
the module metrics.py.</p>
<p>All rating systems in this package have been implemented by exploiting
several functions of NumPy and SciPy libraries in python that
are intended for algebraic and scientific computations.
Particularly, NumPy was used:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>matrices and vectors handling</p></li>
<li><p>linear systems solving</p></li>
<li><p>finding eigenvalues and eigenvectors</p></li>
<li><p>other problems of linear algebra required for the implementation of rating methods</p></li>
</ol>
</div></blockquote>
<p>As for the statistical tests, such as Kendalls’s Tau for the correlation of
ranking lists, SciPy was used.</p>
<dl class="py class">
<dt class="sig sig-object py" id="ratingslib.ratings.Winloss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Winloss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">ratings.WINLOSS</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Winloss" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="ratingslib.ratings.rating.html#ratingslib.ratings.rating.RatingSystem" title="ratingslib.ratings.rating.RatingSystem"><code class="xref py py-class docutils literal notranslate"><span class="pre">RatingSystem</span></code></a></p>
<p>The traditional rating method which is popular in the field of sports.
In the case of sports teams the method takes into account
the total wins of each team. The first-ranked team is the team
with the most wins.
Note that for any kind of items, there are many ways to define the
notion of a hypothetical matchup and then to determine scores and winners.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>version</strong> (<em>str</em><em>, </em><em>default=ratings.WINLOSS</em>) – A string that shows the version of rating system. The available
versions can be found in <a class="reference internal" href="ratingslib.utils.enums.html#ratingslib.utils.enums.ratings" title="ratingslib.utils.enums.ratings"><code class="xref py py-class docutils literal notranslate"><span class="pre">ratingslib.utils.enums.ratings</span></code></a> class.</p></li>
<li><p><strong>normalization</strong> (<em>bool</em><em>, </em><em>default = True</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> then the result will be normalized according to the total
times each item occurs in the dataset.
For example in sport teams set normalization = <code class="docutils literal notranslate"><span class="pre">True</span></code> if the teams
haven’t played same number of games. This means that each element of
W vector is divided by the total number of games played by the
respective team.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Winloss.W">
<span class="sig-name descname"><span class="pre">W</span></span><a class="headerlink" href="#ratingslib.ratings.Winloss.W" title="Permalink to this definition"></a></dt>
<dd><p>The WinLoss vector for items of shape (n,)
where n = the total number of items. Each element of vector represents
the total wins of the respective item.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<p>The following example demonstrates Winloss rating system,
for the 20 first soccer matches that took place during the 2018-2019
season of English Premier League.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.datasets.filenames</span> <span class="kn">import</span> <span class="n">dataset_path</span><span class="p">,</span> <span class="n">FILENAME_EPL_2018_2019_20_GAMES</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.ratings.winloss</span> <span class="kn">import</span> <span class="n">Winloss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filename</span> <span class="o">=</span> <span class="n">dataset_path</span><span class="p">(</span><span class="n">FILENAME_EPL_2018_2019_20_GAMES</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Winloss</span><span class="p">(</span><span class="n">normalization</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">rate_from_file</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="go">              Item  rating  ranking</span>
<span class="go">0          Arsenal     0.0        3</span>
<span class="go">1      Bournemouth     2.0        1</span>
<span class="go">2         Brighton     1.0        2</span>
<span class="go">3          Burnley     0.0        3</span>
<span class="go">4          Cardiff     0.0        3</span>
<span class="go">5          Chelsea     2.0        1</span>
<span class="go">6   Crystal Palace     1.0        2</span>
<span class="go">7          Everton     1.0        2</span>
<span class="go">8           Fulham     0.0        3</span>
<span class="go">9     Huddersfield     0.0        3</span>
<span class="go">10       Leicester     1.0        2</span>
<span class="go">11       Liverpool     2.0        1</span>
<span class="go">12        Man City     2.0        1</span>
<span class="go">13      Man United     1.0        2</span>
<span class="go">14       Newcastle     0.0        3</span>
<span class="go">15     Southampton     0.0        3</span>
<span class="go">16       Tottenham     2.0        1</span>
<span class="go">17         Watford     2.0        1</span>
<span class="go">18        West Ham     0.0        3</span>
<span class="go">19          Wolves     0.0        3</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Winloss.computation_phase">
<span class="sig-name descname"><span class="pre">computation_phase</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Winloss.computation_phase" title="Permalink to this definition"></a></dt>
<dd><p>All the calculations are made in
<a class="reference internal" href="ratingslib.ratings.winloss.html#ratingslib.ratings.winloss.Winloss.create_win_loss_vector" title="ratingslib.ratings.winloss.Winloss.create_win_loss_vector"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ratingslib.ratings.winloss.Winloss.create_win_loss_vector()</span></code></a> method.
Winloss vector is the rating vector.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Winloss.create_win_loss_vector">
<span class="sig-name descname"><span class="pre">create_win_loss_vector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#ratingslib.ratings.Winloss.create_win_loss_vector" title="Permalink to this definition"></a></dt>
<dd><p>Construction of WinLoss vector.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Winloss.preparation_phase">
<span class="sig-name descname"><span class="pre">preparation_phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Winloss.preparation_phase" title="Permalink to this definition"></a></dt>
<dd><p>To be overridden in subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Winloss.rate">
<span class="sig-name descname"><span class="pre">rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#ratingslib.ratings.Winloss.rate" title="Permalink to this definition"></a></dt>
<dd><p>This method computes ratings for a pairwise data.
(e.g. soccer teams games). To be overridden in subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pandas.DataFrame</em>) – The pairwise data.</p></li>
<li><p><strong>items_df</strong> (<em>pandas.DataFrame</em>) – Set of items (e.g. teams) to be rated</p></li>
<li><p><strong>sort</strong> (<em>bool</em><em>, </em><em>default=True.</em>) – If true, the output is sorted by rating value</p></li>
<li><p><strong>columns_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em><em>]</em>) – The column names of data file.
See <code class="docutils literal notranslate"><span class="pre">ratingslib.datasets.parameters.COLUMNS_DICT</span></code> for more
details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>items_df</strong> – The set of items with their rating and ranking.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ratingslib.ratings.Keener">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Keener</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">ratings.KEENER</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Keener" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="ratingslib.ratings.rating.html#ratingslib.ratings.rating.RatingSystem" title="ratingslib.ratings.rating.RatingSystem"><code class="xref py py-class docutils literal notranslate"><span class="pre">RatingSystem</span></code></a></p>
<p>This method has been proposed by James P. Keener in 1993 for football
teams ranking in uneven paired competition <a href="#id23"><span class="problematic" id="id1">[1]_</span></a>.
Keener’s method is based on the theory of nonnegative matrices and forms a
smoothed matrix of scores generated by Laplace’s rule of succession.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>version</strong> (<em>str</em><em>, </em><em>default=ratings.KEENER</em>) – A string that shows the version of rating system. The available
versions can be found in <a class="reference internal" href="ratingslib.utils.enums.html#ratingslib.utils.enums.ratings" title="ratingslib.utils.enums.ratings"><code class="xref py py-class docutils literal notranslate"><span class="pre">ratingslib.utils.enums.ratings</span></code></a> class.</p></li>
<li><p><strong>normalization</strong> (<em>bool</em><em>, </em><em>default = True</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> then the result will be normalized according to the total
times each item occurs in the dataset.
For example in sport teams set normalization = <code class="docutils literal notranslate"><span class="pre">True</span></code> if the teams
haven’t played same number of games.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Keener.A">
<span class="sig-name descname"><span class="pre">A</span></span><a class="headerlink" href="#ratingslib.ratings.Keener.A" title="Permalink to this definition"></a></dt>
<dd><p>The Keener matrix. It has shape (n, n) where n = the total number of
items.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Keener.S">
<span class="sig-name descname"><span class="pre">S</span></span><a class="headerlink" href="#ratingslib.ratings.Keener.S" title="Permalink to this definition"></a></dt>
<dd><p>The matrix containing the cumulative number of points scored by each
item to any other item. It has shape (n, n) where n = the total number
of items.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id2"><span class="brackets">1</span></dt>
<dd><p>Keener, J. P., 1993. The Perron-Frobenius theorem and the ranking of football teams. SIAM Review, 35(1), pp. 80-93</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>The following example demonstrates Keener rating system,
for the 20 first soccer matches that took place during the 2018-2019
season of English Premier League.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.datasets.filenames</span> <span class="kn">import</span> <span class="n">dataset_path</span><span class="p">,</span> <span class="n">FILENAME_EPL_2018_2019_20_GAMES</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.ratings.keener</span> <span class="kn">import</span> <span class="n">Keener</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filename</span> <span class="o">=</span> <span class="n">dataset_path</span><span class="p">(</span><span class="n">FILENAME_EPL_2018_2019_20_GAMES</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Keener</span><span class="p">(</span><span class="n">normalization</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">rate_from_file</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="go">              Item    rating  ranking</span>
<span class="go">0          Arsenal  0.047220       17</span>
<span class="go">1      Bournemouth  0.052874        4</span>
<span class="go">2         Brighton  0.049183       11</span>
<span class="go">3          Burnley  0.048576       14</span>
<span class="go">4          Cardiff  0.048243       16</span>
<span class="go">5          Chelsea  0.052800        5</span>
<span class="go">6   Crystal Palace  0.049870       10</span>
<span class="go">7          Everton  0.051214        7</span>
<span class="go">8           Fulham  0.046829       18</span>
<span class="go">9     Huddersfield  0.046068       20</span>
<span class="go">10       Leicester  0.050701        8</span>
<span class="go">11       Liverpool  0.053796        1</span>
<span class="go">12        Man City  0.053511        2</span>
<span class="go">13      Man United  0.050322        9</span>
<span class="go">14       Newcastle  0.048939       13</span>
<span class="go">15     Southampton  0.048969       12</span>
<span class="go">16       Tottenham  0.052569        6</span>
<span class="go">17         Watford  0.053265        3</span>
<span class="go">18        West Ham  0.046730       19</span>
<span class="go">19          Wolves  0.048320       15</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Keener.compute">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Keener.compute" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Keener.computation_phase">
<span class="sig-name descname"><span class="pre">computation_phase</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Keener.computation_phase" title="Permalink to this definition"></a></dt>
<dd><p>To be overridden in subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Keener.create_keener_matrix">
<span class="sig-name descname"><span class="pre">create_keener_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#ratingslib.ratings.Keener.create_keener_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Construction of Keener matrix and points matrix S</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Keener.h_skew">
<span class="sig-name descname"><span class="pre">h_skew</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Keener.h_skew" title="Permalink to this definition"></a></dt>
<dd><p>Skewing function</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Keener.preparation_phase">
<span class="sig-name descname"><span class="pre">preparation_phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Keener.preparation_phase" title="Permalink to this definition"></a></dt>
<dd><p>To be overridden in subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Keener.rate">
<span class="sig-name descname"><span class="pre">rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#ratingslib.ratings.Keener.rate" title="Permalink to this definition"></a></dt>
<dd><p>This method computes ratings for a pairwise data.
(e.g. soccer teams games). To be overridden in subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pandas.DataFrame</em>) – The pairwise data.</p></li>
<li><p><strong>items_df</strong> (<em>pandas.DataFrame</em>) – Set of items (e.g. teams) to be rated</p></li>
<li><p><strong>sort</strong> (<em>bool</em><em>, </em><em>default=True.</em>) – If true, the output is sorted by rating value</p></li>
<li><p><strong>columns_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em><em>]</em>) – The column names of data file.
See <code class="docutils literal notranslate"><span class="pre">ratingslib.datasets.parameters.COLUMNS_DICT</span></code> for more
details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>items_df</strong> – The set of items with their rating and ranking.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ratingslib.ratings.Massey">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Massey</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">ratings.MASSEY</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Massey" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="ratingslib.ratings.rating.html#ratingslib.ratings.rating.RatingSystem" title="ratingslib.ratings.rating.RatingSystem"><code class="xref py py-class docutils literal notranslate"><span class="pre">RatingSystem</span></code></a></p>
<p>This method was proposed by Kenneth Massey in 1997 for ranking college
football teams <a href="#id24"><span class="problematic" id="id3">[1]_</span></a>.
The Massey method apart from numbers of wins and losses, it also considers
the point score data to rate items via a system of linear equations.
It uses a linear least squares regression to solve a system of
linear equations.
Note that point score data depends on the application, for instance in
soccer teams the points are the number of goals of each team.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>version</strong> (<em>str</em><em>, </em><em>default=ratings.MASSEY</em>) – A string that shows the version of rating system. The available
versions can be found in <a class="reference internal" href="ratingslib.utils.enums.html#ratingslib.utils.enums.ratings" title="ratingslib.utils.enums.ratings"><code class="xref py py-class docutils literal notranslate"><span class="pre">ratingslib.utils.enums.ratings</span></code></a> class.</p></li>
<li><p><strong>data_limit</strong> (<em>int</em><em>, </em><em>default=0</em>) – The parameter data_limit specifies the minimum number of observations
in the dataset. Default is set <code class="docutils literal notranslate"><span class="pre">0</span></code> and indicates no limit.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Massey.Madj">
<span class="sig-name descname"><span class="pre">Madj</span></span><a class="headerlink" href="#ratingslib.ratings.Massey.Madj" title="Permalink to this definition"></a></dt>
<dd><p>The adjusted Massey matrix. The last row of this matrix is replaced
with vector of all ones.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Massey.d_adj">
<span class="sig-name descname"><span class="pre">d_adj</span></span><a class="headerlink" href="#ratingslib.ratings.Massey.d_adj" title="Permalink to this definition"></a></dt>
<dd><p>The adjusted point differentials vector.
The last item of this vector is replaced zero.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id4"><span class="brackets">1</span></dt>
<dd><p>Massey, K. (1997). Statistical models applied to the rating of sports teams.
Statistical models applied to the rating of sports teams.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>The following example demonstrates Massey rating system,
for the 20 first soccer matches that took place during the 2018-2019
season of English Premier League.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.datasets.filenames</span> <span class="kn">import</span> <span class="n">dataset_path</span><span class="p">,</span> <span class="n">FILENAME_EPL_2018_2019_20_GAMES</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.ratings.massey</span> <span class="kn">import</span> <span class="n">Massey</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filename</span> <span class="o">=</span> <span class="n">dataset_path</span><span class="p">(</span><span class="n">FILENAME_EPL_2018_2019_20_GAMES</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Massey</span><span class="p">()</span><span class="o">.</span><span class="n">rate_from_file</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="go">              Item        rating  ranking</span>
<span class="go">0          Arsenal  2.500000e+00       11</span>
<span class="go">1      Bournemouth  4.781250e+00        3</span>
<span class="go">2         Brighton -4.781250e+00       14</span>
<span class="go">3          Burnley -6.031250e+00       17</span>
<span class="go">4          Cardiff  3.031250e+00        9</span>
<span class="go">5          Chelsea  3.250000e+00        8</span>
<span class="go">6   Crystal Palace  5.031250e+00        2</span>
<span class="go">7          Everton -6.281250e+00       18</span>
<span class="go">8           Fulham  2.781250e+00       10</span>
<span class="go">9     Huddersfield  2.220446e-15       12</span>
<span class="go">10       Leicester -5.531250e+00       16</span>
<span class="go">11       Liverpool  7.281250e+00        1</span>
<span class="go">12        Man City  4.750000e+00        4</span>
<span class="go">13      Man United -5.156250e+00       15</span>
<span class="go">14       Newcastle  3.281250e+00        7</span>
<span class="go">15     Southampton -6.656250e+00       19</span>
<span class="go">16       Tottenham  4.531250e+00        5</span>
<span class="go">17         Watford -3.406250e+00       13</span>
<span class="go">18        West Ham  3.531250e+00        6</span>
<span class="go">19          Wolves -6.906250e+00       20</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Massey.computation_phase">
<span class="sig-name descname"><span class="pre">computation_phase</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Massey.computation_phase" title="Permalink to this definition"></a></dt>
<dd><p>To be overridden in subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Massey.create_massey_matrix">
<span class="sig-name descname"><span class="pre">create_massey_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#ratingslib.ratings.Massey.create_massey_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Construction of adjusted Massey matrix (<code class="docutils literal notranslate"><span class="pre">M_adj</span></code>) and adjusted
point differential vector (<code class="docutils literal notranslate"><span class="pre">d_adj</span></code>)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Massey.preparation_phase">
<span class="sig-name descname"><span class="pre">preparation_phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Massey.preparation_phase" title="Permalink to this definition"></a></dt>
<dd><p>To be overridden in subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Massey.rate">
<span class="sig-name descname"><span class="pre">rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#ratingslib.ratings.Massey.rate" title="Permalink to this definition"></a></dt>
<dd><p>This method computes ratings for a pairwise data.
(e.g. soccer teams games). To be overridden in subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pandas.DataFrame</em>) – The pairwise data.</p></li>
<li><p><strong>items_df</strong> (<em>pandas.DataFrame</em>) – Set of items (e.g. teams) to be rated</p></li>
<li><p><strong>sort</strong> (<em>bool</em><em>, </em><em>default=True.</em>) – If true, the output is sorted by rating value</p></li>
<li><p><strong>columns_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em><em>]</em>) – The column names of data file.
See <code class="docutils literal notranslate"><span class="pre">ratingslib.datasets.parameters.COLUMNS_DICT</span></code> for more
details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>items_df</strong> – The set of items with their rating and ranking.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ratingslib.ratings.OffenseDefense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">OffenseDefense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">ratings.OD</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.OffenseDefense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="ratingslib.ratings.rating.html#ratingslib.ratings.rating.RatingSystem" title="ratingslib.ratings.rating.RatingSystem"><code class="xref py py-class docutils literal notranslate"><span class="pre">RatingSystem</span></code></a></p>
<p>Offense-Defense is a modified version of ranking algorithm HITS used
in Ask search engine. This rating system developed by Anjela Govan during
her PhD <a href="#id25"><span class="problematic" id="id5">[1]_</span></a> <a href="#id26"><span class="problematic" id="id6">[2]_</span></a> for sport teams rating. The main idea of this method is
to separate the offensive and defensive strength of each team and the final
rating vector can be generated by combining offensive and defensive lists.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>version</strong> (<em>str</em><em>, </em><em>default=ratings.OD</em>) – A string that shows the version of rating system. The available
versions can be found in <a class="reference internal" href="ratingslib.utils.enums.html#ratingslib.utils.enums.ratings" title="ratingslib.utils.enums.ratings"><code class="xref py py-class docutils literal notranslate"><span class="pre">ratingslib.utils.enums.ratings</span></code></a> class.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>default=0.0001</em>) – Tolerance level</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.OffenseDefense.A">
<span class="sig-name descname"><span class="pre">A</span></span><a class="headerlink" href="#ratingslib.ratings.OffenseDefense.A" title="Permalink to this definition"></a></dt>
<dd><p>Adjacency matrix of items scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.OffenseDefense.P">
<span class="sig-name descname"><span class="pre">P</span></span><a class="headerlink" href="#ratingslib.ratings.OffenseDefense.P" title="Permalink to this definition"></a></dt>
<dd><p>P matrix of OD method.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.OffenseDefense.defense">
<span class="sig-name descname"><span class="pre">defense</span></span><a class="headerlink" href="#ratingslib.ratings.OffenseDefense.defense" title="Permalink to this definition"></a></dt>
<dd><p>Defense rating vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.OffenseDefense.offense">
<span class="sig-name descname"><span class="pre">offense</span></span><a class="headerlink" href="#ratingslib.ratings.OffenseDefense.offense" title="Permalink to this definition"></a></dt>
<dd><p>Offense rating vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.OffenseDefense.error">
<span class="sig-name descname"><span class="pre">error</span></span><a class="headerlink" href="#ratingslib.ratings.OffenseDefense.error" title="Permalink to this definition"></a></dt>
<dd><p>Error until convergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.OffenseDefense.iter">
<span class="sig-name descname"><span class="pre">iter</span></span><a class="headerlink" href="#ratingslib.ratings.OffenseDefense.iter" title="Permalink to this definition"></a></dt>
<dd><p>Number of iterations to produce convergence of both of the Offense and
Defense vectors.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id7"><span class="brackets">1</span></dt>
<dd><p>Govan, A. Y., Langville, A. N., &amp; Meyer, C. D. (2009).
Offense-defense approach to ranking team sports.
Journal of Quantitative Analysis in Sports, 5(1)</p>
</dd>
<dt class="label" id="id8"><span class="brackets">2</span></dt>
<dd><p>Govan, A. Y. (2008). Ranking Theory with Application to Popular Sports.
Ph.D. dissertation, North Carolina State University.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>The following example demonstrates Offense-Defense rating system,
for the 20 first soccer matches that took place during the 2018-2019
season of English Premier League.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.datasets.filenames</span> <span class="kn">import</span> <span class="n">dataset_path</span><span class="p">,</span> <span class="n">FILENAME_EPL_2018_2019_20_GAMES</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.ratings.od</span> <span class="kn">import</span> <span class="n">OffenseDefense</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filename</span> <span class="o">=</span> <span class="n">dataset_path</span><span class="p">(</span><span class="n">FILENAME_EPL_2018_2019_20_GAMES</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">OffenseDefense</span><span class="p">(</span><span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span><span class="o">.</span><span class="n">rate_from_file</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="go">              Item        rating  ranking</span>
<span class="go">0          Arsenal  1.934298e+00       12</span>
<span class="go">1      Bournemouth  1.312759e+06        3</span>
<span class="go">2         Brighton  3.712401e+00       11</span>
<span class="go">3          Burnley  4.103263e+05        4</span>
<span class="go">4          Cardiff  4.757391e-04       14</span>
<span class="go">5          Chelsea  4.576599e+00       10</span>
<span class="go">6   Crystal Palace  1.049852e+03        7</span>
<span class="go">7          Everton  2.080318e-07       16</span>
<span class="go">8           Fulham  1.532621e-12       20</span>
<span class="go">9     Huddersfield  5.583941e-01       13</span>
<span class="go">10       Leicester  1.876215e+04        6</span>
<span class="go">11       Liverpool  3.403605e+12        1</span>
<span class="go">12        Man City  5.284698e+00        9</span>
<span class="go">13      Man United  6.223487e+00        8</span>
<span class="go">14       Newcastle  9.071493e-08       18</span>
<span class="go">15     Southampton  2.510896e-07       15</span>
<span class="go">16       Tottenham  9.071797e-08       17</span>
<span class="go">17         Watford  1.864760e+06        2</span>
<span class="go">18        West Ham  2.311787e+05        5</span>
<span class="go">19          Wolves  3.793810e-11       19</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.OffenseDefense.computation_phase">
<span class="sig-name descname"><span class="pre">computation_phase</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.OffenseDefense.computation_phase" title="Permalink to this definition"></a></dt>
<dd><p>Compute offense, defense vectors and overall ratings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.OffenseDefense.create_score_matrices">
<span class="sig-name descname"><span class="pre">create_score_matrices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#ratingslib.ratings.OffenseDefense.create_score_matrices" title="Permalink to this definition"></a></dt>
<dd><p>Construct score matrix A and P</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.OffenseDefense.preparation_phase">
<span class="sig-name descname"><span class="pre">preparation_phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.OffenseDefense.preparation_phase" title="Permalink to this definition"></a></dt>
<dd><p>Create A and P matrices</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.OffenseDefense.rate">
<span class="sig-name descname"><span class="pre">rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#ratingslib.ratings.OffenseDefense.rate" title="Permalink to this definition"></a></dt>
<dd><p>This method computes ratings for a pairwise data.
(e.g. soccer teams games). To be overridden in subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pandas.DataFrame</em>) – The pairwise data.</p></li>
<li><p><strong>items_df</strong> (<em>pandas.DataFrame</em>) – Set of items (e.g. teams) to be rated</p></li>
<li><p><strong>sort</strong> (<em>bool</em><em>, </em><em>default=True.</em>) – If true, the output is sorted by rating value</p></li>
<li><p><strong>columns_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em><em>]</em>) – The column names of data file.
See <code class="docutils literal notranslate"><span class="pre">ratingslib.datasets.parameters.COLUMNS_DICT</span></code> for more
details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>items_df</strong> – The set of items with their rating and ranking.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Markov</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">ratings.MARKOV</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stats_markov_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Set</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Markov" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="ratingslib.ratings.rating.html#ratingslib.ratings.rating.RatingSystem" title="ratingslib.ratings.rating.RatingSystem"><code class="xref py py-class docutils literal notranslate"><span class="pre">RatingSystem</span></code></a></p>
<p>This class implements the Markov (GeM - Generalized Markov Method)
rating system.
GeM was first used by graduate students, Angela Govan <a href="#id27"><span class="problematic" id="id9">[1]_</span></a> and
Luke Ingram <a href="#id28"><span class="problematic" id="id10">[2]_</span></a> to successfully rank NFL football and NCAA basketball
teams respectively.
The Markov (GeM) method is related to the famous PageRank method <a class="footnote-reference brackets" href="#id14" id="id11">3</a> and
it uses parts of finite Markov chains and graph theory in order to
generate ratings of n objects in a finite set.
Not only sports but also any problem that can be represented as a weighted
directed graph can be solved using GeM model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>version</strong> (<em>str</em><em>, </em><em>default=ratings.MARKOV</em>) – A string that shows the version of rating system. The available
versions can be found in <a class="reference internal" href="ratingslib.utils.enums.html#ratingslib.utils.enums.ratings" title="ratingslib.utils.enums.ratings"><code class="xref py py-class docutils literal notranslate"><span class="pre">ratingslib.utils.enums.ratings</span></code></a> class.</p></li>
<li><p><strong>b</strong> (<em>float</em><em>, </em><em>default=1</em>) – The damping factor. Valid numbers are in the range [0,1]</p></li>
<li><p><strong>stats_markov_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Dict</em><em>[</em><em>Any</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>]</em><em>, </em><em>default=None</em>) – <p>A dictionary containing statistics details for the method. For instance
for soccer teams rating, the following dictionary
<code class="docutils literal notranslate"><span class="pre">stats_markov_dict</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">stats_markov_dict</span> <span class="o">=</span> <span class="p">{</span>
<span class="s1">&#39;TotalWins&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;VOTE&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;ITEM_I&#39;</span><span class="p">:</span> <span class="s1">&#39;FTHG&#39;</span><span class="p">,</span> <span class="s1">&#39;ITEM_J&#39;</span><span class="p">:</span> <span class="s1">&#39;FTAG&#39;</span><span class="p">,</span>
               <span class="s1">&#39;METHOD&#39;</span><span class="p">:</span> <span class="s1">&#39;VotingWithLosses&#39;</span><span class="p">},</span>
<span class="s1">&#39;TotalGoals&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;VOTE&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;ITEM_I&#39;</span><span class="p">:</span> <span class="s1">&#39;FTHG&#39;</span><span class="p">,</span> <span class="s1">&#39;ITEM_J&#39;</span><span class="p">:</span> <span class="s1">&#39;FTAG&#39;</span><span class="p">,</span>
                <span class="s1">&#39;METHOD&#39;</span><span class="p">:</span> <span class="s1">&#39;WinnersAndLosersVotePoint&#39;</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>specifies the following details:</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">TotalGoals</span></code> and <code class="docutils literal notranslate"><span class="pre">TotalWins</span></code> are the names of two statistics</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'VOTE'</span> <span class="pre">:</span> <span class="pre">10</span></code> means that the vote is 10. Those votes will be
converted as weights. The statistics in this example are equally
weighted</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'ITEM_I':</span> <span class="pre">'FTHG'</span></code> and <code class="docutils literal notranslate"><span class="pre">'ITEM_J':</span> <span class="pre">'FTAG'</span></code> are the column names for home
and away team respectively</p></li>
<li><p>The key <code class="docutils literal notranslate"><span class="pre">'METHOD'</span></code> specifies which method constructs the
voting matrix. The available methods are:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'VotingWithLosses'</span></code> when the losing team casts a
number of votes equal to the margin of victory in its matchup
with a stronger opponent.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'WinnersAndLosersVotePoint'</span></code> when both the winning and losing
teams vote with the number of points given up.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'LosersVotePointDiff'</span></code> when the losing team cast a number of
votes</p></li>
</ol>
</li>
</ul>
</div></blockquote>
<dl class="simple">
<dt>See also the implementation of the method</dt><dd><p><a class="reference internal" href="#ratingslib.ratings.Markov.create_voting_matrix" title="ratingslib.ratings.Markov.create_voting_matrix"><code class="xref py py-meth docutils literal notranslate"><span class="pre">create_voting_matrix()</span></code></a></p>
</dd>
</dl>
</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.stats">
<span class="sig-name descname"><span class="pre">stats</span></span><a class="headerlink" href="#ratingslib.ratings.Markov.stats" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary that maps voting and stochastic arrays.
The keys that starts with V map the voting matrices and with S map
the stochastic matrices</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Dict[str, np.ndarray]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.params">
<span class="sig-name descname"><span class="pre">params</span></span><a class="headerlink" href="#ratingslib.ratings.Markov.params" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary that maps parameters to their values.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Dict[str, Optional[Dict[str, Dict[Any, Any]]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.stochastic_matrix">
<span class="sig-name descname"><span class="pre">stochastic_matrix</span></span><a class="headerlink" href="#ratingslib.ratings.Markov.stochastic_matrix" title="Permalink to this definition"></a></dt>
<dd><p>A Stochastic Markov  matrix is a square matrix where each entry
describes the probability that the item will vote for the respective
item.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.stochastic_matrix_asch">
<span class="sig-name descname"><span class="pre">stochastic_matrix_asch</span></span><a class="headerlink" href="#ratingslib.ratings.Markov.stochastic_matrix_asch" title="Permalink to this definition"></a></dt>
<dd><p>A Stochastic Markov matrix that is irreducible</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.pi_steady">
<span class="sig-name descname"><span class="pre">pi_steady</span></span><a class="headerlink" href="#ratingslib.ratings.Markov.pi_steady" title="Permalink to this definition"></a></dt>
<dd><p>The stationary vector or dominant eigenvector of the
<a class="reference internal" href="#ratingslib.ratings.Markov.stochastic_matrix" title="ratingslib.ratings.Markov.stochastic_matrix"><code class="xref py py-attr docutils literal notranslate"><span class="pre">stochastic_matrix</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.group">
<span class="sig-name descname"><span class="pre">group</span></span><a class="headerlink" href="#ratingslib.ratings.Markov.group" title="Permalink to this definition"></a></dt>
<dd><p>Set of statistics names</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>Set[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>ValueError</strong> – Value of <cite>b</cite> ∈ [0, 1]</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>The following example demonstrate GeM rating system,
for the 20 first soccer matches that took place during the 2018-2019
season of English Premier League.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.datasets.filenames</span> <span class="kn">import</span> <span class="n">dataset_path</span><span class="p">,</span> <span class="n">FILENAME_EPL_2018_2019_20_GAMES</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.ratings.markov</span> <span class="kn">import</span> <span class="n">Markov</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filename</span> <span class="o">=</span> <span class="n">dataset_path</span><span class="p">(</span><span class="n">FILENAME_EPL_2018_2019_20_GAMES</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">votes</span> <span class="o">=</span> <span class="p">{</span>
<span class="go">        &#39;TW&#39;: {</span>
<span class="go">            &#39;VOTE&#39;: 10,</span>
<span class="go">            &#39;ITEM_I&#39;: &#39;FTHG&#39;,</span>
<span class="go">            &#39;ITEM_J&#39;: &#39;FTAG&#39;,</span>
<span class="go">            &#39;METHOD&#39;: &#39;VotingWithLosses&#39;},</span>
<span class="go">        &#39;TG&#39;: {</span>
<span class="go">            &#39;VOTE&#39;: 10,</span>
<span class="go">            &#39;ITEM_I&#39;: &#39;FTHG&#39;,</span>
<span class="go">            &#39;ITEM_J&#39;: &#39;FTAG&#39;,</span>
<span class="go">            &#39;METHOD&#39;: &#39;WinnersAndLosersVotePoint&#39;},</span>
<span class="go">        &#39;TST&#39;: {</span>
<span class="go">            &#39;VOTE&#39;: 10,</span>
<span class="go">            &#39;ITEM_I&#39;: &#39;HST&#39;,</span>
<span class="go">            &#39;ITEM_J&#39;: &#39;AST&#39;,</span>
<span class="go">            &#39;METHOD&#39;: &#39;WinnersAndLosersVotePoint&#39;},</span>
<span class="go">        &#39;TS&#39;: {</span>
<span class="go">            &#39;VOTE&#39;: 10,</span>
<span class="go">            &#39;ITEM_I&#39;: &#39;HS&#39;,</span>
<span class="go">            &#39;ITEM_J&#39;: &#39;AS&#39;,</span>
<span class="go">            &#39;METHOD&#39;: &#39;WinnersAndLosersVotePoint&#39;},</span>
<span class="go">    }</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Markov</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="mf">0.85</span><span class="p">,</span> <span class="n">stats_markov_dict</span><span class="o">=</span><span class="n">votes</span><span class="p">)</span><span class="o">.</span><span class="n">rate_from_file</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="go">                Item    rating  ranking</span>
<span class="go">    0          Arsenal  0.050470       11</span>
<span class="go">    1      Bournemouth  0.039076       15</span>
<span class="go">    2         Brighton  0.051460       10</span>
<span class="go">    3          Burnley  0.071596        2</span>
<span class="go">    4          Cardiff  0.024085       20</span>
<span class="go">    5          Chelsea  0.045033       13</span>
<span class="go">    6   Crystal Palace  0.037678       16</span>
<span class="go">    7          Everton  0.066307        3</span>
<span class="go">    8           Fulham  0.036356       17</span>
<span class="go">    9     Huddersfield  0.032164       19</span>
<span class="go">    10       Leicester  0.055491        7</span>
<span class="go">    11       Liverpool  0.056879        6</span>
<span class="go">    12        Man City  0.048325       12</span>
<span class="go">    13      Man United  0.061052        4</span>
<span class="go">    14       Newcastle  0.035814       18</span>
<span class="go">    15     Southampton  0.051716        9</span>
<span class="go">    16       Tottenham  0.053079        8</span>
<span class="go">    17         Watford  0.082788        1</span>
<span class="go">    18        West Ham  0.041824       14</span>
<span class="go">    19          Wolves  0.058807        5</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id12"><span class="brackets">1</span></dt>
<dd><p>Govan, A. Y. (2008). Ranking Theory with Application to Popular Sports.
Ph.D. dissertation, North Carolina State University.</p>
</dd>
<dt class="label" id="id13"><span class="brackets">2</span></dt>
<dd><p>Ingram, L. C. (2007). Ranking NCAA sports teams with Linear algebra.
Ranking NCAA sports teams with Linear algebra. Charleston</p>
</dd>
<dt class="label" id="id14"><span class="brackets"><a class="fn-backref" href="#id11">3</a></span></dt>
<dd><p>Sergey Brin and Lawrence Page. The Anatomy of a Large-Scale
Hypertextual Web Search Engine. Computer Networks and
ISDN Systems, 33:107-17, 1998.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.set_group">
<span class="sig-name descname"><span class="pre">set_group</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Markov.set_group" title="Permalink to this definition"></a></dt>
<dd><p>Set the group of statistics.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.do_stochastic">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">do_stochastic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">voting_matrix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Markov.do_stochastic" title="Permalink to this definition"></a></dt>
<dd><p>Normalize the rows of the voting matrix to develop a
stochastic transition probability matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>voting_matrix</strong> (<em>List</em><em>[</em><em>list</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>stochastic_matrix</strong> – Stochastic matrix built from the corresponding voting</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.compute">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stochastic_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Markov.compute" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.computation_phase">
<span class="sig-name descname"><span class="pre">computation_phase</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Markov.computation_phase" title="Permalink to this definition"></a></dt>
<dd><p>Compute the stationary vector or dominant
eigenvector of the transpose of irreducible matrix. Stationary vector
is the rating vector.
Note:  irreducible matrix is the <a class="reference internal" href="#ratingslib.ratings.Markov.stochastic_matrix_asch" title="ratingslib.ratings.Markov.stochastic_matrix_asch"><code class="xref py py-attr docutils literal notranslate"><span class="pre">stochastic_matrix_asch</span></code></a> and
stationary vector is the <a class="reference internal" href="#ratingslib.ratings.Markov.pi_steady" title="ratingslib.ratings.Markov.pi_steady"><code class="xref py py-attr docutils literal notranslate"><span class="pre">pi_steady</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.create_voting_matrix">
<span class="sig-name descname"><span class="pre">create_voting_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">voting_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'VotingWithLosses'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'WinnersAndLosersVotePoint'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'LosersVotePointDiff'</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_name_home</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_name_away</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#ratingslib.ratings.Markov.create_voting_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Selection of method for developing voting matrix.
The available methods are:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'VotingWithLosses'</span></code> when the losing team casts a
number of votes equal to the margin of victory in its matchup
with a stronger opponent.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'WinnersAndLosersVotePoint'</span></code> when both the winning and losing
teams vote with the number of points given up.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'LosersVotePointDiff'</span></code> when the losing team cast a number of
votes.</p></li>
</ol>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.preparation_phase">
<span class="sig-name descname"><span class="pre">preparation_phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Markov.preparation_phase" title="Permalink to this definition"></a></dt>
<dd><p>During preparation phase, voting and stochastic matrices are
constructed for each statistic according to the method specified
in the dictionary of attr:<cite>stats_markov_dict</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.rate">
<span class="sig-name descname"><span class="pre">rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#ratingslib.ratings.Markov.rate" title="Permalink to this definition"></a></dt>
<dd><p>This method computes ratings for a pairwise data.
(e.g. soccer teams games). To be overridden in subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pandas.DataFrame</em>) – The pairwise data.</p></li>
<li><p><strong>items_df</strong> (<em>pandas.DataFrame</em>) – Set of items (e.g. teams) to be rated</p></li>
<li><p><strong>sort</strong> (<em>bool</em><em>, </em><em>default=True.</em>) – If true, the output is sorted by rating value</p></li>
<li><p><strong>columns_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em><em>]</em>) – The column names of data file.
See <code class="docutils literal notranslate"><span class="pre">ratingslib.datasets.parameters.COLUMNS_DICT</span></code> for more
details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>items_df</strong> – The set of items with their rating and ranking.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Markov.validate_stats_markov_dict">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate_stats_markov_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stats_markov_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Markov.validate_stats_markov_dict" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ratingslib.ratings.AccuRate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">AccuRate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">ratings.ACCURATE</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">starting_point</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.AccuRate" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="ratingslib.ratings.rating.html#ratingslib.ratings.rating.RatingSystem" title="ratingslib.ratings.rating.RatingSystem"><code class="xref py py-class docutils literal notranslate"><span class="pre">RatingSystem</span></code></a></p>
<p>This class implements the <code class="xref py py-class docutils literal notranslate"><span class="pre">ratingslib.ratings.RatingSystem</span></code> abstract
class using an approach called AccuRate for the computation of
rating values as described in the paper <a href="#id29"><span class="problematic" id="id15">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>version</strong> (<em>str</em><em>, </em><em>default=ratings.ACCURATE</em>) – A string that shows the version of rating system. The available
versions can be found in <a class="reference internal" href="ratingslib.utils.enums.html#ratingslib.utils.enums.ratings" title="ratingslib.utils.enums.ratings"><code class="xref py py-class docutils literal notranslate"><span class="pre">ratingslib.utils.enums.ratings</span></code></a> class.</p></li>
<li><p><strong>starting_point</strong> (<em>int</em>) – the value where the initial rating starts</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id16"><span class="brackets">1</span></dt>
<dd><p>Kyriakides, G., Talattinis, K., &amp; Stephanides, G. (2017).
A Hybrid Approach to Predicting Sports Results and an AccuRATE Rating System.
International Journal of Applied and Computational Mathematics, 3(1), 239–254.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>The following example demonstrates Accurate rating system
for a simple soccer competition where only two teams participate,
team “Good” and team “Better”.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.datasets.filenames</span> <span class="kn">import</span> <span class="n">dataset_path</span><span class="p">,</span> <span class="n">FILENAME_ACCURATE_PAPER_EXAMPLE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.ratings.accurate</span> <span class="kn">import</span> <span class="n">AccuRate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filename</span> <span class="o">=</span> <span class="n">dataset_path</span><span class="p">(</span><span class="n">FILENAME_ACCURATE_PAPER_EXAMPLE</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">AccuRate</span><span class="p">()</span><span class="o">.</span><span class="n">rate_from_file</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="go">     Team    rating  ranking</span>
<span class="go">0  Better  1.681793        1</span>
<span class="go">1    Good -1.587401        2</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.AccuRate.create_rating_vector">
<span class="sig-name descname"><span class="pre">create_rating_vector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#ratingslib.ratings.AccuRate.create_rating_vector" title="Permalink to this definition"></a></dt>
<dd><p>Calculates ratings according to pairs of items data.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.AccuRate.computation_phase">
<span class="sig-name descname"><span class="pre">computation_phase</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.AccuRate.computation_phase" title="Permalink to this definition"></a></dt>
<dd><p>Nothing to compute, all the calculations are made in
<a class="reference internal" href="ratingslib.ratings.accurate.html#ratingslib.ratings.accurate.AccuRate.create_rating_vector" title="ratingslib.ratings.accurate.AccuRate.create_rating_vector"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ratingslib.ratings.accurate.AccuRate.create_rating_vector()</span></code></a> method</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.AccuRate.preparation_phase">
<span class="sig-name descname"><span class="pre">preparation_phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.AccuRate.preparation_phase" title="Permalink to this definition"></a></dt>
<dd><p>To be overridden in subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.AccuRate.rate">
<span class="sig-name descname"><span class="pre">rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#ratingslib.ratings.AccuRate.rate" title="Permalink to this definition"></a></dt>
<dd><p>This method computes ratings for a pairwise data.
(e.g. soccer teams games). To be overridden in subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pandas.DataFrame</em>) – The pairwise data.</p></li>
<li><p><strong>items_df</strong> (<em>pandas.DataFrame</em>) – Set of items (e.g. teams) to be rated</p></li>
<li><p><strong>sort</strong> (<em>bool</em><em>, </em><em>default=True.</em>) – If true, the output is sorted by rating value</p></li>
<li><p><strong>columns_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em><em>]</em>) – The column names of data file.
See <code class="docutils literal notranslate"><span class="pre">ratingslib.datasets.parameters.COLUMNS_DICT</span></code> for more
details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>items_df</strong> – The set of items with their rating and ranking.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ratingslib.ratings.Elo">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Elo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">ratings.ELOWIN</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">K</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">40</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">HA</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">400</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">starting_point</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1500</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Elo" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="ratingslib.ratings.rating.html#ratingslib.ratings.rating.RatingSystem" title="ratingslib.ratings.rating.RatingSystem"><code class="xref py py-class docutils literal notranslate"><span class="pre">RatingSystem</span></code></a></p>
<p>Elo ranking system developed by Arpad Elo <a href="#id30"><span class="problematic" id="id17">[1]_</span></a> in order to
rank chess players, this system has been adopted by quite a lot of sports
and organizations.</p>
<p>This implementation includes two basic versions of Elo:</p>
<blockquote>
<div><ul class="simple">
<li><p>The first is called EloWin and takes into account total wins of
items. In soccer teams the final outcome determines the
winner.</p></li>
<li><p>The second is called EloPoint and takes into account items scores.
In soccer the points are the goals scored be each team.</p></li>
</ul>
</div></blockquote>
<p>Note that for any kind of items, there are many ways to define the
notion of a hypothetical matchup and then to determine scores and winners.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>version</strong> (<em>str</em><em>, </em><em>default=ratings.ELOWIN</em>) – a string that shows version of rating system</p></li>
<li><p><strong>K</strong> (<em>int</em><em>, </em><em>default=40</em>) – K-factor is the maximum possible adjustment per pair of items.
For soccer, K–factor plays an important role because it balances the
deviation for the goal difference in the game against prior ratings.</p></li>
<li><p><strong>HA</strong> (<em>int</em><em>, </em><em>default=0</em>) – The home advantage factor is an adjustment that is used due to the fact
that home teams tend to score more goals. Elo system applies the
home-field advantage factor, by adding it to the rating of home team.
Many implementations of Elo model for soccer, set the home-field
advantage to 100. The default value <code class="docutils literal notranslate"><span class="pre">0</span></code> means that method does not
take into account home advantage factor.</p></li>
<li><p><strong>ks</strong> (<em>float</em><em>, </em><em>default=400</em>) – Parameter ξ (<code class="docutils literal notranslate"><span class="pre">ks</span></code>) affects the spread of ratings and comes from
logistic function. For chess and soccer games usually, ξ is set to 400.</p></li>
<li><p><strong>starting_point</strong> (<em>float</em><em>, </em><em>default = 1500</em>) – The value where the initial rating starts</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Soccer application and Elo:
According to the type of soccer tournament the following values represents
the K-Factor value suggested by several internet sites <a href="#id31"><span class="problematic" id="id18">[2]_</span></a>:</p>
<blockquote>
<div><ul class="simple">
<li><p>World Cup Finals = 60</p></li>
<li><p>Continental Championship Finals and Major Intercontinental
tournaments = 50</p></li>
<li><p>World Cup Qualifiers and Major Tournaments = 40</p></li>
<li><p>All other tournaments = 30</p></li>
<li><p>Friendly matches = 20</p></li>
</ul>
</div></blockquote>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id19"><span class="brackets">1</span></dt>
<dd><p>Elo, A. E. (1978). The rating of chessplayers, past and present. Arco Pub.</p>
</dd>
<dt class="label" id="id20"><span class="brackets">2</span></dt>
<dd><p><a class="reference external" href="http://www.eloratings.net/about">http://www.eloratings.net/about</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>The following examples demonstrates the EloWin and the EloPoint version,
for the 20 first soccer matches that took place during the 2018-2019
season of English Premier League.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.datasets.filenames</span> <span class="kn">import</span> <span class="n">dataset_path</span><span class="p">,</span> <span class="n">FILENAME_EPL_2018_2019_20_GAMES</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.ratings.elo</span> <span class="kn">import</span> <span class="n">Elo</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.utils.enums</span> <span class="kn">import</span> <span class="n">ratings</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filename</span> <span class="o">=</span> <span class="n">dataset_path</span><span class="p">(</span><span class="n">FILENAME_EPL_2018_2019_20_GAMES</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Elo</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="n">ratings</span><span class="o">.</span><span class="n">ELOWIN</span><span class="p">,</span> <span class="n">starting_point</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">rate_from_file</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="go">              Item     rating  ranking</span>
<span class="go">0          Arsenal -37.707535       12</span>
<span class="go">1      Bournemouth  37.707535        3</span>
<span class="go">2         Brighton   2.292465        5</span>
<span class="go">3          Burnley -18.849977        9</span>
<span class="go">4          Cardiff -20.000000       10</span>
<span class="go">5          Chelsea  37.707535        3</span>
<span class="go">6   Crystal Palace   0.000000        7</span>
<span class="go">7          Everton  20.000000        4</span>
<span class="go">8           Fulham -37.707535       12</span>
<span class="go">9     Huddersfield -37.707535       12</span>
<span class="go">10       Leicester   1.150023        6</span>
<span class="go">11       Liverpool  40.000000        1</span>
<span class="go">12        Man City  37.707535        3</span>
<span class="go">13      Man United  -2.292465        8</span>
<span class="go">14       Newcastle -20.000000       10</span>
<span class="go">15     Southampton -20.000000       10</span>
<span class="go">16       Tottenham  37.707535        3</span>
<span class="go">17         Watford  38.849977        2</span>
<span class="go">18        West Ham -37.707535       12</span>
<span class="go">19          Wolves -21.150023       11</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Elo</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="n">ratings</span><span class="o">.</span><span class="n">ELOPOINT</span><span class="p">,</span> <span class="n">starting_point</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">rate_from_file</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="go">              Item     rating  ranking</span>
<span class="go">0          Arsenal -11.592411       17</span>
<span class="go">1      Bournemouth  12.658841        5</span>
<span class="go">2         Brighton  -6.337388       14</span>
<span class="go">3          Burnley  -6.091179       13</span>
<span class="go">4          Cardiff  -9.654647       15</span>
<span class="go">5          Chelsea  13.592411        4</span>
<span class="go">6   Crystal Palace   0.191876       10</span>
<span class="go">7          Everton   4.000000        8</span>
<span class="go">8           Fulham -15.861198       18</span>
<span class="go">9     Huddersfield -21.846379       20</span>
<span class="go">10       Leicester   6.230248        7</span>
<span class="go">11       Liverpool  23.141457        1</span>
<span class="go">12        Man City  19.846379        2</span>
<span class="go">13      Man United   0.337388        9</span>
<span class="go">14       Newcastle  -4.345353       12</span>
<span class="go">15     Southampton  -4.000000       11</span>
<span class="go">16       Tottenham   9.861198        6</span>
<span class="go">17         Watford  16.091179        3</span>
<span class="go">18        West Ham -15.992174       19</span>
<span class="go">19          Wolves -10.230248       16</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Elo.create_rating_vector">
<span class="sig-name descname"><span class="pre">create_rating_vector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#ratingslib.ratings.Elo.create_rating_vector" title="Permalink to this definition"></a></dt>
<dd><p>Calculates Elo ratings according to pairs of items data.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Elo.computation_phase">
<span class="sig-name descname"><span class="pre">computation_phase</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Elo.computation_phase" title="Permalink to this definition"></a></dt>
<dd><p>Nothing to compute, all computations are made in
<a class="reference internal" href="ratingslib.ratings.elo.html#ratingslib.ratings.elo.Elo.create_rating_vector" title="ratingslib.ratings.elo.Elo.create_rating_vector"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ratingslib.ratings.elo.Elo.create_rating_vector()</span></code></a> method</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Elo.preparation_phase">
<span class="sig-name descname"><span class="pre">preparation_phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Elo.preparation_phase" title="Permalink to this definition"></a></dt>
<dd><p>To be overridden in subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Elo.rate">
<span class="sig-name descname"><span class="pre">rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#ratingslib.ratings.Elo.rate" title="Permalink to this definition"></a></dt>
<dd><p>This method computes ratings for a pairwise data.
(e.g. soccer teams games). To be overridden in subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pandas.DataFrame</em>) – The pairwise data.</p></li>
<li><p><strong>items_df</strong> (<em>pandas.DataFrame</em>) – Set of items (e.g. teams) to be rated</p></li>
<li><p><strong>sort</strong> (<em>bool</em><em>, </em><em>default=True.</em>) – If true, the output is sorted by rating value</p></li>
<li><p><strong>columns_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em><em>]</em>) – The column names of data file.
See <code class="docutils literal notranslate"><span class="pre">ratingslib.datasets.parameters.COLUMNS_DICT</span></code> for more
details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>items_df</strong> – The set of items with their rating and ranking.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Elo.prepare_for_gridsearch_tuning">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">prepare_for_gridsearch_tuning</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">version_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ks_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">HA_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="ratingslib.ratings.rating.html#ratingslib.ratings.rating.RatingSystem" title="ratingslib.ratings.rating.RatingSystem"><span class="pre">RatingSystem</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#ratingslib.ratings.Elo.prepare_for_gridsearch_tuning" title="Permalink to this definition"></a></dt>
<dd><p>Create instances that are intended for tuning parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>version_list</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List of Elo versions</p></li>
<li><p><strong>k_range</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>float</em><em>]</em><em>]</em><em>, </em><em>default=None</em>) – List of k values. If <code class="docutils literal notranslate"><span class="pre">None</span></code> then
parameter is not intended for tuning</p></li>
<li><p><strong>ks_range</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>float</em><em>]</em><em>]</em><em>, </em><em>default=None</em>) – List of ks values. If <code class="docutils literal notranslate"><span class="pre">None</span></code> then
parameter is not intended for tuning</p></li>
<li><p><strong>HA_range</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>float</em><em>]</em><em>]</em><em>, </em><em>default=None</em>) – List of HA values. If <code class="docutils literal notranslate"><span class="pre">None</span></code> then
parameter is not intended for tuning</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>rating_systems_dict</strong> – Dictionary that contains Elo instances with the
parameters we want for tuning.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ratingslib.ratings.Colley">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Colley</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">ratings.COLLEY</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Colley" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="ratingslib.ratings.rating.html#ratingslib.ratings.rating.RatingSystem" title="ratingslib.ratings.rating.RatingSystem"><code class="xref py py-class docutils literal notranslate"><span class="pre">RatingSystem</span></code></a></p>
<p>This class implements the Colley rating system.
This system was proposed by astrophysicist Dr. Wesley Colley in 2001 for
ranking sports teams. Colley’s method <a href="#id32"><span class="problematic" id="id21">[1]_</span></a> makes use of an idea from
probability theory, known as Laplace’s ‘‘rule of succession’’.
In fact, it is a modified form of the win-loss method, which uses the
percentage of wins of each team.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>version</strong> (<em>str</em><em>, </em><em>default=ratings.COLLEY</em>) – A string that shows the version of rating system. The available
versions can be found in <a class="reference internal" href="ratingslib.utils.enums.html#ratingslib.utils.enums.ratings" title="ratingslib.utils.enums.ratings"><code class="xref py py-class docutils literal notranslate"><span class="pre">ratingslib.utils.enums.ratings</span></code></a> class.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Colley.C">
<span class="sig-name descname"><span class="pre">C</span></span><a class="headerlink" href="#ratingslib.ratings.Colley.C" title="Permalink to this definition"></a></dt>
<dd><p>The Colley matrix of shape (n,n) where n = the total number of
items.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ratingslib.ratings.Colley.b">
<span class="sig-name descname"><span class="pre">b</span></span><a class="headerlink" href="#ratingslib.ratings.Colley.b" title="Permalink to this definition"></a></dt>
<dd><p>The right-hand side vector <code class="docutils literal notranslate"><span class="pre">b</span></code> of shape (n,)
where n = the total number of items.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id22"><span class="brackets">1</span></dt>
<dd><p>Colley, W. (2002). Colley’s bias free college football ranking method: The Colley Matrix Explained.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>The following example demonstrates Colley rating system,
for the 20 first soccer matches that took place during the 2018-2019
season of English Premier League.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.datasets.filenames</span> <span class="kn">import</span> <span class="n">dataset_path</span><span class="p">,</span> <span class="n">FILENAME_EPL_2018_2019_20_GAMES</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ratingslib.ratings.colley</span> <span class="kn">import</span> <span class="n">Colley</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filename</span> <span class="o">=</span> <span class="n">dataset_path</span><span class="p">(</span><span class="n">FILENAME_EPL_2018_2019_20_GAMES</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Colley</span><span class="p">()</span><span class="o">.</span><span class="n">rate_from_file</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="go">              Item    rating  ranking</span>
<span class="go">0          Arsenal  0.333333       16</span>
<span class="go">1      Bournemouth  0.686012        3</span>
<span class="go">2         Brighton  0.562500        6</span>
<span class="go">3          Burnley  0.401786       10</span>
<span class="go">4          Cardiff  0.394345       11</span>
<span class="go">5          Chelsea  0.666667        5</span>
<span class="go">6   Crystal Palace  0.501488        8</span>
<span class="go">7          Everton  0.562500        6</span>
<span class="go">8           Fulham  0.293155       17</span>
<span class="go">9     Huddersfield  0.333333       16</span>
<span class="go">10       Leicester  0.473214        9</span>
<span class="go">11       Liverpool  0.712798        2</span>
<span class="go">12        Man City  0.666667        5</span>
<span class="go">13      Man United  0.508929        7</span>
<span class="go">14       Newcastle  0.391369       12</span>
<span class="go">15     Southampton  0.366071       14</span>
<span class="go">16       Tottenham  0.671131        4</span>
<span class="go">17         Watford  0.741071        1</span>
<span class="go">18        West Ham  0.349702       15</span>
<span class="go">19          Wolves  0.383929       13</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Colley.computation_phase">
<span class="sig-name descname"><span class="pre">computation_phase</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Colley.computation_phase" title="Permalink to this definition"></a></dt>
<dd><p>Solve the system Cr=b to obtain the Colley rating vector r.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Colley.create_colley_matrix">
<span class="sig-name descname"><span class="pre">create_colley_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#ratingslib.ratings.Colley.create_colley_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Construction of Colley coefficient matrix <code class="docutils literal notranslate"><span class="pre">C</span></code> and right-hand
side vector <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Colley.preparation_phase">
<span class="sig-name descname"><span class="pre">preparation_phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.Colley.preparation_phase" title="Permalink to this definition"></a></dt>
<dd><p>To be overridden in subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.Colley.rate">
<span class="sig-name descname"><span class="pre">rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#ratingslib.ratings.Colley.rate" title="Permalink to this definition"></a></dt>
<dd><p>This method computes ratings for a pairwise data.
(e.g. soccer teams games). To be overridden in subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pandas.DataFrame</em>) – The pairwise data.</p></li>
<li><p><strong>items_df</strong> (<em>pandas.DataFrame</em>) – Set of items (e.g. teams) to be rated</p></li>
<li><p><strong>sort</strong> (<em>bool</em><em>, </em><em>default=True.</em>) – If true, the output is sorted by rating value</p></li>
<li><p><strong>columns_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em><em>]</em>) – The column names of data file.
See <code class="docutils literal notranslate"><span class="pre">ratingslib.datasets.parameters.COLUMNS_DICT</span></code> for more
details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>items_df</strong> – The set of items with their rating and ranking.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ratingslib.ratings.kendall_tau_table">
<span class="sig-name descname"><span class="pre">kendall_tau_table</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ratings_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">DataFrame</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_out</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#ratingslib.ratings.kendall_tau_table" title="Permalink to this definition"></a></dt>
<dd><p>Kendall Tau comparison of ranking lists.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ratings_dict</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>pd.DataFrame</em><em>]</em>) – Dictionary that maps names to ratings. Note that ratings are stored in
a <cite>pandas.DataFrame</cite>.</p></li>
<li><p><strong>print_out</strong> (<em>bool</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> then print results table.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>kendall_results</strong> – Table of Kendall tau results. The lower diagonal elements represent Kendall’s tau values
of each pair, while the upper diagonal elements the p-values of each pair from the
two-sided hypothesis test, whose null hypothesis is an absence of association</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>List[List[float]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ratingslib.ratings.RatingAggregation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">RatingAggregation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">ratings.AGGREGATIONMARKOV</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">votes_or_weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.9</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.RatingAggregation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="ratingslib.ratings.rating.html#ratingslib.ratings.rating.RatingSystem" title="ratingslib.ratings.rating.RatingSystem"><code class="xref py py-class docutils literal notranslate"><span class="pre">RatingSystem</span></code></a></p>
<p>Class for Rating aggregation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>version</strong> (<em>str</em><em>, </em><em>default=ratings.AGGREGATIONMARKOV</em>) – A string that shows the version of rating system. The available
versions can be found in <a class="reference internal" href="ratingslib.utils.enums.html#ratingslib.utils.enums.ratings" title="ratingslib.utils.enums.ratings"><code class="xref py py-class docutils literal notranslate"><span class="pre">ratingslib.utils.enums.ratings</span></code></a> class.</p></li>
<li><p><strong>votes_or_weights</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em><em>]</em>) – Votes or weigths for matrices</p></li>
<li><p><strong>b</strong> (<em>float</em><em>, </em><em>optional</em>) – Valid if aggregation method = ratings.AGGREGATIONMARKOV, by default 0.9</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.RatingAggregation.calc_rating_distances">
<span class="sig-name descname"><span class="pre">calc_rating_distances</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rating_column_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#ratingslib.ratings.RatingAggregation.calc_rating_distances" title="Permalink to this definition"></a></dt>
<dd><p>Calculate and create pairwise matrix by taking into account
the rating differences (as distances)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pd.DataFrame</em>) – dataset of ratings</p></li>
<li><p><strong>rating_column_name</strong> (<em>str</em>) – which is the rating column of dataset</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>matrix</strong> – rating distances matrix</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.RatingAggregation.calc_dict_rating_distances">
<span class="sig-name descname"><span class="pre">calc_dict_rating_distances</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rating_columns</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#ratingslib.ratings.RatingAggregation.calc_dict_rating_distances" title="Permalink to this definition"></a></dt>
<dd><p>Calculate and create dictionary of pairwise matrices by
taking into account the rating differences (as distances).
Each column represents the rating method name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pd.DataFrame</em>) – dataset of ratings</p></li>
<li><p><strong>rating_columns</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of columns that refers to ratings</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>matrices_dict</strong> – dictionary that maps column to rating distance matrix</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Dict[str, np.ndarray]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.RatingAggregation.rating_aggregation">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">rating_aggregation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">matrices_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">votes_or_weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">ratings.AGGREGATIONMARKOV</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.9</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#ratingslib.ratings.RatingAggregation.rating_aggregation" title="Permalink to this definition"></a></dt>
<dd><p>Rating aggregation from rating lists</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>matrices_dict</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>np.ndarray</em><em>]</em>) – Dictionary that maps name to rating distance matrix</p></li>
<li><p><strong>votes_or_weights</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em><em>]</em>) – Votes or weigths for matrices</p></li>
<li><p><strong>aggregation_method</strong> (<em>str</em><em>, </em><em>default=ratings.AGGREGATIONMARKOV</em>) – Name of aggregation method</p></li>
<li><p><strong>b</strong> (<em>float</em><em>, </em><em>optional</em>) – Valid if aggregation method = ratings.AGGREGATIONMARKOV, by default 0.9</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>rating</strong> – Aggregated rating vector</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If matrices_dict and votes_or_weights parameters
    don’t have the same size</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.RatingAggregation.computation_phase">
<span class="sig-name descname"><span class="pre">computation_phase</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.RatingAggregation.computation_phase" title="Permalink to this definition"></a></dt>
<dd><p>To be overridden in subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.RatingAggregation.preparation_phase">
<span class="sig-name descname"><span class="pre">preparation_phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.RatingAggregation.preparation_phase" title="Permalink to this definition"></a></dt>
<dd><p>To be overridden in subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.RatingAggregation.rate">
<span class="sig-name descname"><span class="pre">rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#ratingslib.ratings.RatingAggregation.rate" title="Permalink to this definition"></a></dt>
<dd><p>This method computes ratings for a pairwise data.
(e.g. soccer teams games). To be overridden in subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pandas.DataFrame</em>) – The pairwise data.</p></li>
<li><p><strong>items_df</strong> (<em>pandas.DataFrame</em>) – Set of items (e.g. teams) to be rated</p></li>
<li><p><strong>sort</strong> (<em>bool</em><em>, </em><em>default=True.</em>) – If true, the output is sorted by rating value</p></li>
<li><p><strong>columns_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em><em>]</em>) – The column names of data file.
See <code class="docutils literal notranslate"><span class="pre">ratingslib.datasets.parameters.COLUMNS_DICT</span></code> for more
details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>items_df</strong> – The set of items with their rating and ranking.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ratingslib.ratings.RankingAggregation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">RankingAggregation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">ratings.RANKINGAVG</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.RankingAggregation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="ratingslib.ratings.rating.html#ratingslib.ratings.rating.RatingSystem" title="ratingslib.ratings.rating.RatingSystem"><code class="xref py py-class docutils literal notranslate"><span class="pre">RatingSystem</span></code></a></p>
<p>Class for Ranking Aggregation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>version</strong> (<em>str</em><em>, </em><em>default=ratings.RANKINGAVG</em>) – A string that shows the version of rating system. The available
versions can be found in <a class="reference internal" href="ratingslib.utils.enums.html#ratingslib.utils.enums.ratings" title="ratingslib.utils.enums.ratings"><code class="xref py py-class docutils literal notranslate"><span class="pre">ratingslib.utils.enums.ratings</span></code></a> class.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.RankingAggregation.ranking_aggregation">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ranking_aggregation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rating_columns</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">ratings.RANKINGAVG</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#ratingslib.ratings.RankingAggregation.ranking_aggregation" title="Permalink to this definition"></a></dt>
<dd><p>Ranking aggregation from ranking lists</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pd.DataFrame</em>) – Rating values are the columns of DataFrame</p></li>
<li><p><strong>aggregation_method</strong> (<em>str</em><em>, </em><em>default=ratings.AGGREGATIONAVG</em>) – Name of aggregation method</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>rating</strong> – Aggregated rating vector</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If matrices_dict and votes_or_weights parameters
    don’t have the same size</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.RankingAggregation.computation_phase">
<span class="sig-name descname"><span class="pre">computation_phase</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.RankingAggregation.computation_phase" title="Permalink to this definition"></a></dt>
<dd><p>All the calculations are made in
<code class="xref py py-meth docutils literal notranslate"><span class="pre">ratingslib.ratings.aggregations.RankingAggregation.ranking_aggregation()</span></code> method.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.RankingAggregation.preparation_phase">
<span class="sig-name descname"><span class="pre">preparation_phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ratingslib.ratings.RankingAggregation.preparation_phase" title="Permalink to this definition"></a></dt>
<dd><p>To be overridden in subclasses.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ratingslib.ratings.RankingAggregation.rate">
<span class="sig-name descname"><span class="pre">rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">columns_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#ratingslib.ratings.RankingAggregation.rate" title="Permalink to this definition"></a></dt>
<dd><p>This method computes ratings for a pairwise data.
(e.g. soccer teams games). To be overridden in subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_df</strong> (<em>pandas.DataFrame</em>) – The pairwise data.</p></li>
<li><p><strong>items_df</strong> (<em>pandas.DataFrame</em>) – Set of items (e.g. teams) to be rated</p></li>
<li><p><strong>sort</strong> (<em>bool</em><em>, </em><em>default=True.</em>) – If true, the output is sorted by rating value</p></li>
<li><p><strong>columns_dict</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em><em>]</em>) – The column names of data file.
See <code class="docutils literal notranslate"><span class="pre">ratingslib.datasets.parameters.COLUMNS_DICT</span></code> for more
details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>items_df</strong> – The set of items with their rating and ranking.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this heading"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.tests.html">ratingslib.ratings.tests package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="ratingslib.ratings.tests.html#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.tests.test_all.html">ratingslib.ratings.tests.test_all module</a></li>
<li class="toctree-l3"><a class="reference internal" href="ratingslib.ratings.tests.test_rating.html">ratingslib.ratings.tests.test_rating module</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.accurate.html">ratingslib.ratings.accurate module</a></li>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.aggregation.html">ratingslib.ratings.aggregation module</a></li>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.colley.html">ratingslib.ratings.colley module</a></li>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.elo.html">ratingslib.ratings.elo module</a></li>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.keener.html">ratingslib.ratings.keener module</a></li>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.markov.html">ratingslib.ratings.markov module</a></li>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.massey.html">ratingslib.ratings.massey module</a></li>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.methods.html">ratingslib.ratings.methods module</a></li>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.metrics.html">ratingslib.ratings.metrics module</a></li>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.od.html">ratingslib.ratings.od module</a></li>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.rating.html">ratingslib.ratings.rating module</a></li>
<li class="toctree-l1"><a class="reference internal" href="ratingslib.ratings.winloss.html">ratingslib.ratings.winloss module</a></li>
</ul>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ratingslib.datasets.soccer.html" class="btn btn-neutral float-left" title="ratingslib.datasets.soccer module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ratingslib.ratings.tests.html" class="btn btn-neutral float-right" title="ratingslib.ratings.tests package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Kyriacos Talattinis.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>